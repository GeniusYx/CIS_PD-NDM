{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data preprocessing \n",
    "### load raw files -> generate clips -> compute features-> aggregate into a matrix of features and scores\n",
    "** Pandas version required to load pickle files is 0.20.1 or greater **\n",
    "\n",
    "* Try classifying symptom presence from \"typing\", \"walking\" and \"finger-to-nose\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pickle #to save files\n",
    "from itertools import product\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from PreprocessFcns import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#-- For interactive plots--\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path declarations for code\n",
    "# If running across multiple users / platforms, can use the platform library with conditionals\n",
    "# using platform.system() and/or platform.release() to quickly switch between paths\n",
    "\n",
    "path = 'D:\\CIS-PD Study\\Subjects' # path to where the subjects' raw data from mc10cloud are stored\n",
    "folder_path = 'D:\\CIS-PD Study' # path to the study folder\n",
    "dict_path = 'D:\\CIS-PD Study\\Data_dict' # folder where each subject's data dictionaries are located as .pkl files\n",
    "scores_path = 'D:\\CIS-PD Study\\Scores' # folder where tasks scores are stored as .xls format\n",
    "features_path = 'D:\\CIS-PD Study\\FeatureMatrix' # folder to store features files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete is a list of all performed activities in the MC10 app -- change as needed\n",
    "# complete = list(['Heart Rate Variability', 'MDS-UPDRS #1: Finger Tapping',\n",
    "#            'MDS-UPDRS #2: Hand Movements', 'MDS-UPDRS #3: Pronation-Supination',\n",
    "#            'MDS-UPDRS #4: Toe Tapping', 'MDS-UPDRS #5: Leg Agility',\n",
    "#            'MDS-UPDRS #6: Arising from Chair', 'MDS-UPDRS #7: Gait',\n",
    "#            'MDS-UPDRS #8: Postural Stability', 'MDS-UPDRS #9: Postural Hand Tremor',\n",
    "#            'MDS-UPDRS #10: Kinetic Hand Tremor', 'MDS-UPDRS #11: Rest Tremor',\n",
    "#            'Motor #1: Standing', 'Motor #2: Walking', 'Motor #3: Walking while Counting',\n",
    "#            'Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements',\n",
    "#            'Motor #6: Sit to Stand', 'Motor #7: Drawing on Paper',\n",
    "#            'Motor #8: Typing on a Computer', 'Motor #9: Nuts and Bolts',\n",
    "#            'Motor #10: Drinking Water', 'Motor #11: Organizing Folder',\n",
    "#            'Motor #12: Folding Towels', 'Motor #13: Sitting', 'Unstructured'])\n",
    "\n",
    "## for dummy data set:\n",
    "complete = list(['Heart Rate Variability', 'MDS-UPDRS #7: Gait', 'Motor #2: Walking'])\n",
    "\n",
    "# complete_noRest = complete\n",
    "# complete_noRest.remove('MDS-UPDRS #11: Rest Tremor')\n",
    "\n",
    "def process_annotations(path):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Processes raw annotations file from MC10 app to extract start / end timestamps and remove unnecessary data\n",
    "#\n",
    "# Inputs:  path - filepath of the subject folder containing annotations.csv\n",
    "#\n",
    "# Outputs: df - dataframe containing list of activities and their start / end timestamps\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    df = pd.read_csv(os.path.join(path, 'annotations.csv'))\n",
    "    del df['Timestamp (ms)']\n",
    "    del df['AnnotationId']\n",
    "    del df['AuthorId']\n",
    "    del df['Value']\n",
    "    \n",
    "    df = df[(df.EventType != 'Testing Day')]\n",
    "    \n",
    "    sorter = set(df.EventType.unique().flatten())\n",
    "    sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "        \n",
    "    df['EventType_Rank'] = df['EventType'].map(sorterIndex)\n",
    "    df['Cycle'] = df.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    del df['EventType_Rank']\n",
    "    \n",
    "    # hard code workaround for Heart Rate Variability specific to that task, comment if not using HRV\n",
    "    df[df['EventType'].str.contains('Heart')] = df[df['EventType'].str.contains('Heart')].replace(to_replace={'Cycle': {1: 'NaN', 2: 'NaN', 3: 'NaN', 4: 'NaN'}})\n",
    "    \n",
    "    df = df.reset_index(drop=True).set_index('EventType')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper fcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_data(SubID, path):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# For a given subject, extracts and separates accelerometer, gyroscope, and EMG/ECG data into trials and sensor per activity\n",
    "#\n",
    "# Inputs: SubID - string of numbers corresponding to the subject ID\n",
    "#         path - system path to corresponding subject's raw data files\n",
    "#\n",
    "# Outputs: act_dict - dictionary of both MDS-UPDRS and Motor Assessment activities separated by trial, sensor location, and\n",
    "#                     accelerometer + gyroscope or accelerometer + EMG/ECG data. Every key within this dictionary is a dictionary\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    timestamps = process_annotations(path)\n",
    "#     timestamps = fix_errors(SubID, timestamps)\n",
    "#     timestamps = add_unstruct_data(timestamps)\n",
    "    \n",
    "    \n",
    "#     ## Hard coded list of sensors needed to be reversed in X- and Y- accel/gyro Day 1 data for Subject 1024\n",
    "#     ## comment, is a workaround for a very specific problem from just one subject\n",
    "#     reverse_sensors_1024 = list(['anterior_thigh_left', 'anterior_thigh_right',\n",
    "#                                  'distal_lateral_shank_left', 'distal_lateral_shank_right'])\n",
    "    \n",
    "    # Creates list of sensor locations from folders within subject's raw data directory\n",
    "    locations = [locs for locs in os.listdir(path) if os.path.isdir(os.path.join(path, locs))]\n",
    "    \n",
    "    # Creates dictionary of empty dataframes to merge all accelerometer, gyroscope, and EMG/ECG data for each sensor\n",
    "    accel = {locs: pd.DataFrame() for locs in locations}\n",
    "    gyro = {locs: pd.DataFrame() for locs in locations}\n",
    "    elec = {locs: pd.DataFrame() for locs in locations}\n",
    "    \n",
    "    # Finds and merges all accelerometer, gyroscope, and EMG/ECG data for each sensor, retains datetime information\n",
    "    for root, dirs, files in os.walk(path, topdown=True):\n",
    "        for filenames in files:\n",
    "            ## The following has only been tested on Windows 7 -- pathlib.Path may perform differntly\n",
    "            ## on Linux machines. If you run into an error, please raise an Issue on GitHub\n",
    "            \n",
    "            if filenames.endswith('accel.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                accel[location] = accel[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('gyro.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                gyro[location] = gyro[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith(('elec.csv', 'emg.csv', 'ecg.csv', 'ekg.csv')):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                elec[location] = elec[location].append(temp_df)\n",
    "                \n",
    "#     # Fix for subjects missing both MDS-UPDRS #11: Rest Tremor trials, updated 4/2/2018\n",
    "#     if SubID in ('1024', '1030', '1032', '1053'):\n",
    "#         complete_acts = complete_noRest\n",
    "#     else:\n",
    "#         complete_acts = complete\n",
    "    complete_acts = complete\n",
    "                \n",
    "    # Complete dictionary of all activities\n",
    "    act_dict = {acts: pd.DataFrame() for acts in complete_acts}\n",
    "\n",
    "    # Populate dictionary keys per activity with every iteration / trial\n",
    "    for activities in complete_acts:\n",
    "        \n",
    "        startSize = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "        \n",
    "        if np.size(startSize) == 1:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)']\n",
    "        else:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)'].values\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)'].values\n",
    "\n",
    "        # Create trial dictionary with each key containing all sensor data related with each activity's trial\n",
    "        trial_dict = {trials: pd.DataFrame() for trials in range(0, np.size(startTimestamp))}\n",
    "\n",
    "        # Populate trial directory keys\n",
    "        for trials in range(0, np.size(startTimestamp)):\n",
    "\n",
    "            if np.size(startSize) == 1:\n",
    "                startTime = startTimestamp\n",
    "                endTime = endTimestamp\n",
    "            else:\n",
    "                startTime = startTimestamp[trials]\n",
    "                endTime = endTimestamp[trials]\n",
    "\n",
    "            # Create sensor location dictionary with each key corresponding to sensor locations\n",
    "            sensor_dict = {locs: pd.DataFrame() for locs in locations}\n",
    "\n",
    "            # Extract sensor data and populate sensor_dict with sensor data\n",
    "            for location in locations:\n",
    "\n",
    "                data = {'accel': pd.DataFrame(), 'gyro': pd.DataFrame(), 'elec': pd.DataFrame()}\n",
    "\n",
    "                if not accel[location].empty:\n",
    "                    accelData = accel[location]\n",
    "                    data['accel'] = accelData[(accelData.index >= startTime) & (accelData.index <= endTime)]\n",
    "                    \n",
    "#                     # Hard coded reversal of accel data since sensors were placed upside-down for one subject\n",
    "#                     if SubID == '1024' and location in reverse_sensors_1024 and trials != (np.size(startTimestamp)-1):\n",
    "#                         data['accel'].loc[:, ('Accel X (g)')] = -1*data['accel'].loc[:, ('Accel X (g)')]\n",
    "#                         data['accel'].loc[:, ('Accel Y (g)')] = -1*data['accel'].loc[:, ('Accel Y (g)')]\n",
    "\n",
    "                if not gyro[location].empty:\n",
    "                    gyroData = gyro[location]\n",
    "                    data['gyro'] = gyroData[(gyroData.index >= startTime) & (gyroData.index <= endTime)]\n",
    "                    \n",
    "#                     ## Hard coded reversal of accel data since sensors were placed upside-down for one subject                    \n",
    "#                     if SubID == '1024' and location in reverse_sensors_1024 and trials != (np.size(startTimestamp)-1):\n",
    "#                         data['gyro'].loc[:, ('Gyro X (°/s)')] = -1*data['gyro'].loc[:, ('Gyro X (°/s)')]\n",
    "#                         data['gyro'].loc[:, ('Gyro Y (°/s)')] = -1*data['gyro'].loc[:, ('Gyro Y (°/s)')]\n",
    "\n",
    "                if not elec[location].empty:\n",
    "                    elecData = elec[location]\n",
    "                    data['elec'] = elecData[(elecData.index >= startTime) & (elecData.index <= endTime)]\n",
    "                    \n",
    "                # Manual fix for 1016 and 1046 right and left hand sensors swapped locations in 4 week visit data    \n",
    "                if SubID in list(['1016', '1046']) and location == 'dorsal_hand_right' and trials == (np.size(startTimestamp)-1):\n",
    "                    sensor_dict['dorsal_hand_left'] = data\n",
    "                elif SubID in list(['1016', '1046']) and location == 'dorsal_hand_left' and trials == (np.size(startTimestamp)-1):\n",
    "                    sensor_dict['dorsal_hand_right'] = data\n",
    "                else:\n",
    "                    sensor_dict[location] = data\n",
    "\n",
    "            trial_dict[trials] = sensor_dict\n",
    "\n",
    "        act_dict[activities] = trial_dict\n",
    "    \n",
    "    return act_dict, timestamps\n",
    "    \n",
    "\n",
    "def gen_unimodal_data(input_dict, side, unimodal_acts=None, shift=50):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Reduces certain activities and subgroup of sensors in act_dict to only include data during active periods\n",
    "# i.e right hand sensor excludes data when left hand is performing task (e.g. supination-pronation)\n",
    "#\n",
    "# Inputs: input_dict - dictionary of both MDS-UPDRS and Motor Assessment activities separated by trial, sensor location, and\n",
    "#                      accelerometer + gyroscope or accelerometer + EMG/ECG data\n",
    "#         side - string, 'left' or 'right' dictating how to cut the input_dict\n",
    "#         unimodal_acts - list of tasks to consider for data reduction, default value is None and uses list generated within\n",
    "#                         function that cycles through all unimodal tasks. Can feed list to only look at specific subset\n",
    "#         shift - shifting value of starting and ending index of reduced data. Default value is 50\n",
    "#\n",
    "# Outputs: act_dict - returns dictionary with appropriate tasks and sensors limited in scope to active data\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    output_dict = copy.deepcopy(input_dict) # deep copy to create separate copy instead of modifying pointer to cut data\n",
    "    \n",
    "    if unimodal_acts and unimodal_acts is not list:\n",
    "        \n",
    "        raise Error(\"unimodal_acts must be of type list\")\n",
    "        \n",
    "    elif not unimodal_acts:\n",
    "        unimodal_acts = list(['Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements'])\n",
    "      \n",
    "    for acts in unimodal_acts:\n",
    "\n",
    "        for trials in range(0, len(input_dict[acts].keys())):\n",
    "            \n",
    "            for sensors in input_dict[acts][trials].keys():\n",
    "                \n",
    "                for data in input_dict[acts][trials][sensors].keys():\n",
    "\n",
    "                    index = len(input_dict[acts][trials][sensors][data]);\n",
    "                    \n",
    "                    if side == 'right':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][shift:((index//2)-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "                    elif side == 'left':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][((index//2)+shift):(index-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def add_unstruct_data(input_timestamp):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Includes unstructured activity data between tested and timestamped activities/trials in generated act_dict\n",
    "# \n",
    "# Inputs: input_timestamp - timestamp after processing and fix_errors\n",
    "#\n",
    "# Outputs: unstructured_timestamps - timestamp dataframe with start and end timestamps for unstructured\n",
    "#                                    activities. Organized within act_dict as an additional activity\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    timestamps = input_timestamp.loc[input_timestamp.index != 'Heart Rate Variability']\n",
    "    \n",
    "    startTime = []; endTime = []; Cycle = []; Event = [];\n",
    "\n",
    "    for num in range(1,6):\n",
    "        startTime.append(timestamps[timestamps['Cycle']==num]['Stop Timestamp (ms)'].iat[-1])\n",
    "        endTime.append(timestamps[timestamps['Cycle']==(num+1)]['Start Timestamp (ms)'].iat[0])\n",
    "        Cycle.append(num)\n",
    "        Event.append('Unstructured')\n",
    "\n",
    "    d = {'EventType': Event,\n",
    "         'Start Timestamp (ms)': startTime,\n",
    "         'Stop Timestamp (ms)': endTime,\n",
    "         'Cycle': Cycle}\n",
    "\n",
    "    unstruct = pd.DataFrame(data=d, columns=['EventType', 'Start Timestamp (ms)', 'Stop Timestamp (ms)', 'Cycle'])\n",
    "    unstruct = unstruct.set_index('EventType')\n",
    "    \n",
    "    unstructured_timestamps = input_timestamp.append(unstruct)\n",
    "    \n",
    "    return unstructured_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Error Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines functions to fix specific errors with the timestamps for each activity. Example of errors:\n",
    "* Merge: left and right sided activities exist as two separate, consecutive timestamps as the result of experimenter error, and need to be merged together\n",
    "* Late: the timestamp start time is later than the actual activity start time\n",
    "* Early: the timestamp start time is earlier than the actual activity start time\n",
    "* Duplicate: duplicate, identical timestamps are created as the result of a bug\n",
    "* Split: one timestamp erroneously encompasses two activities and needs to be cut at a specific point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_errors(participant, timestamps):\n",
    "#input: 4 digit participant ID\n",
    "#Output: ErrorList - A list of the errors needed to be fixed for the participant\n",
    "#        timestamps - The dataFrame with the errors corrected for the participant\n",
    "#        errordf - The dataFrame containing the remaining errors less the ones just fixed\n",
    "\n",
    "    participant = int(participant) #convert to int, input SubID is a str\n",
    "    errordf = pd.read_excel(os.path.join(folder_path, 'PD_errorWorkbook.xlsx'))\n",
    "    errPar = errordf[errordf['Participant'] == participant]\n",
    "    errorActivity = (errPar['Activity'])\n",
    "    error = errPar['Error']\n",
    "    cycle = errPar['Cycle']\n",
    "    day = errPar['Day']\n",
    "    time = errPar['Time Adjusted (sec)']\n",
    "    desc = errPar['Type']\n",
    "    errorAndActivity = errPar[['Error','Activity']]\n",
    "    \n",
    "    # Hard coded relabel for one activity in Subject 1049's timestamps\n",
    "    if participant == 1049:\n",
    "        for i in range(0,len(timestamps)-1):\n",
    "            row = timestamps.iloc[i]\n",
    "        \n",
    "            if timestamps.index[i] == 'MDS-UPDRS #6: Arising from Chair' and row['Start Timestamp (ms)'] == 1505757980933:\n",
    "                timestamps.reset_index(inplace=True)\n",
    "                #timestamps.set_value(i, 'EventType', 'Motor #6: Sit to Stand')\n",
    "                #.set_value is deprecated as of pandas 21.0, .at used instead for label-based\n",
    "                timestamps.at[i, 'EventType'] = 'Motor #6: Sit to Stand'\n",
    "                timestamps.set_index('EventType', inplace=True)\n",
    "    \n",
    "    for a in range(0,len(error)):\n",
    "        errAct = (errorActivity.iloc[a])\n",
    "        errType = (error.iloc[a])\n",
    "        errCycle = (cycle.iloc[a])\n",
    "        errTime = (time.iloc[a])\n",
    "        errDesc = (desc.iloc[a])\n",
    "        errDay = (day.iloc[a])\n",
    "        if errDay == 'Day 2':\n",
    "            if 'MDS' in errAct:\n",
    "                errCycle = errCycle + 2\n",
    "            elif 'Motor' in errAct:\n",
    "                errCycle = errCycle + 5\n",
    "\n",
    "        if errType == 'Merge':\n",
    "            timestamps = fix_merge(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Late':\n",
    "            timestamps = fix_late(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Early':\n",
    "            timestamps = fix_early(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Duplicate':\n",
    "            timestamps = fix_duplicate(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay,participant)\n",
    "\n",
    "        elif errType == 'Split':\n",
    "            timestamps = fix_split(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "            \n",
    "    for a in range(0,len(error)):\n",
    "        errAct = (errorActivity.iloc[a])\n",
    "        errType = (error.iloc[a])\n",
    "        errCycle = (cycle.iloc[a])\n",
    "        errTime = (time.iloc[a])\n",
    "        errDesc = (desc.iloc[a])\n",
    "        errDay = (day.iloc[a])\n",
    "        \n",
    "        if errType == 'Absent':\n",
    "            timestamps = fix_absent(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "    \n",
    "    \n",
    "    tempappend = errordf.loc[errPar.index.values]\n",
    "    errordf = errordf.drop(errPar.index.values)\n",
    "    \n",
    "    print('Subject ' + str(participant) + ' had ' + str(len(error)) + ' errors fixed.')\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def fix_late(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "# subtracts time from the beginning or ending timestamp of the designated activity\n",
    "\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        startRow = timestamps.iloc[i]\n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            errorLocation = i\n",
    "      \n",
    "            if errType == 'End':\n",
    "                startTime = startRow['Stop Timestamp (ms)']\n",
    "                startTime = startTime - (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "        \n",
    "            else:\n",
    "                startTime = startRow['Start Timestamp (ms)']\n",
    "                startTime = startTime - (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Start Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "     \n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def fix_early(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "# adds time to the beginning or ending timestamp of the designated activity\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        startRow = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            errorLocation = i\n",
    "            \n",
    "            if errType == 'End':\n",
    "                startTime = startRow[1]\n",
    "                startTime = startTime + (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "\n",
    "            else:\n",
    "                startTime = startRow[0]\n",
    "                startTime = startTime + (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Start Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def fix_merge(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "\n",
    "    for i in range(0,len(timestamps)-2):\n",
    "        nextRow = timestamps.iloc[i+1]\n",
    "        startRow = timestamps.iloc[i]\n",
    "\n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            timeEnd = nextRow['Stop Timestamp (ms)']\n",
    "            ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "            # timestamps.set_value(i,ii,timeEnd,takeable=True)\n",
    "            timestamps.iat[i,ii] = timeEnd\n",
    "            # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "            timestamps = pd.concat([timestamps.iloc[:(i+1)],timestamps.iloc[(i+2):]])\n",
    "\n",
    "        timestamps.reset_index(inplace=True)\n",
    "        timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "        timestamps.set_index('EventType',inplace=True)\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "                \n",
    "\n",
    "def fix_split(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        row = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and row['Cycle'] == errCycle:\n",
    "            timeStart1 = row['Start Timestamp (ms)']\n",
    "            timeEnd2 = row['Stop Timestamp (ms)']\n",
    "            timeChange = errTime\n",
    "            timeEnd1 = timeStart1 + timeChange\n",
    "            timeStart2 = timeEnd1\n",
    "            idx = complete.index(errAct)\n",
    "            ErrorActivity2 = complete[idx+1]\n",
    "            ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "            # timestamps.set_value(i,ii,timeEnd1,takeable=True)\n",
    "            timestamps.iat[i,ii] = timeEnd1\n",
    "            # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "            line = pd.DataFrame({\"Start Timestamp (ms)\":timeEnd1,\"Stop Timestamp (ms)\":timeEnd2,\"Cycle\":errCycle},index=[ErrorActivity2])\n",
    "            timestamps = pd.concat([timestamps.iloc[:(i+1)],line,timestamps.iloc[(i+1):]])\n",
    "            \n",
    "            timestamps.reset_index(inplace=True)\n",
    "            colnames = timestamps.columns.tolist()\n",
    "            colnames[colnames.index('index')] = 'EventType'\n",
    "            timestamps.columns = colnames\n",
    "            timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "            timestamps.set_index('EventType',inplace=True)\n",
    "           \n",
    "    return timestamps\n",
    "\n",
    "            \n",
    "\n",
    "def fix_duplicate(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay,participant):\n",
    "\n",
    "    for i in range(0,len(timestamps)-2):\n",
    "        row = timestamps.iloc[i]\n",
    "        if participant == 1054 and timestamps.index[i] == 'Motor #8: Typing on a Computer':\n",
    "            if timestamps.index[i] == errAct and row['Cycle'] == errCycle+1:\n",
    "                timestamps = pd.concat([timestamps.iloc[:(i)],timestamps.iloc[(i+1):]])\n",
    "            \n",
    "        elif timestamps.index[i] == errAct and row['Cycle'] == errCycle:\n",
    "            timestamps = pd.concat([timestamps.iloc[:i],timestamps.iloc[(i+1):]])\n",
    "            \n",
    "    timestamps.reset_index(inplace=True)\n",
    "    timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    timestamps.set_index('EventType',inplace=True)\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "def fix_absent(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "    \n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        row = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and row['Cycle'] == errCycle and errDay != 'Day 2':\n",
    "\n",
    "            for j in range(i-1,len(timestamps)-1):\n",
    "                row = timestamps.iloc[j]\n",
    "                \n",
    "                if timestamps.index[j] == errAct:\n",
    "                    cyclenum = row['Cycle']\n",
    "                    newCycle = cyclenum + 1\n",
    "                    ii = timestamps.columns.get_loc('Cycle')\n",
    "                    # timestamps.set_value(j,ii,newCycle,takeable=True)\n",
    "                    timestamps.iat[j,ii] = newCycle\n",
    "                    # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "    \n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Error</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time Adjusted (sec)</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004</td>\n",
       "      <td>MDS-UPDRS #9: Postural Hand Tremor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Split</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>MDS-UPDRS #10: Kinetic Hand Tremor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Split Into</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>Motor #4: Finger to Nose</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Merge</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Motor #4: Finger to Nose</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Merge</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>MDS-UPDRS #6: Arising from Chair</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not tested</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant                            Activity  Cycle       Error    Day  \\\n",
       "0         1004  MDS-UPDRS #9: Postural Hand Tremor    1.0       Split  Day 1   \n",
       "1         1004  MDS-UPDRS #10: Kinetic Hand Tremor    1.0  Split Into  Day 1   \n",
       "2         1004            Motor #4: Finger to Nose    1.0       Merge  Day 1   \n",
       "3         1004            Motor #4: Finger to Nose    2.0       Merge  Day 1   \n",
       "4         1004    MDS-UPDRS #6: Arising from Chair    2.0      Absent  Day 1   \n",
       "\n",
       "   Time Adjusted (sec)        Type  \n",
       "0                  5.0         NaN  \n",
       "1                  NaN         NaN  \n",
       "2                  NaN         NaN  \n",
       "3                  NaN         NaN  \n",
       "4                  NaN  Not tested  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ErrorDF is an example of the formatting of the errorWorkbook that the above error functions work off of\n",
    "# Check the GitHub wiki for more information\n",
    "errordf = pd.read_excel(os.path.join(folder_path, 'PD_errorWorkbook.xlsx'))\n",
    "errordf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionaries from sensor data from all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004dict.pkl', '1016dict.pkl', '1018dict.pkl', '1019dict.pkl', '1020dict.pkl', '1024dict.pkl', '1029dict.pkl', '1030dict.pkl', '1032dict.pkl', '1038dict.pkl', '1044dict.pkl', '1046dict.pkl', '1047dict.pkl', '1049dict.pkl', '1051dict.pkl', '1052dict.pkl', '1053dict.pkl', '1054dict.pkl', '1055dict.pkl', '1056dict.pkl']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(dict_path))\n",
    "print(len(os.listdir(dict_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001', '1004', '1016', '1018', '1019', '1020', '1024', '1029', '1030', '1032', '1038', '1044', '1046', '1047', '1049', '1051', '1052', '1053', '1054', '1055', '1056']\n",
      "['1001']\n"
     ]
    }
   ],
   "source": [
    "#all subj data files in repository\n",
    "d = os.listdir(path)\n",
    "f = [filename[0:4] for filename in d if filename.startswith('1')] #need to update to skip existing files in /data\n",
    "print(f)\n",
    "#existing data dictionary files\n",
    "fd = os.listdir(dict_path)\n",
    "fd = [x[:4] for x in fd] #ignore FX at end\n",
    "print(list(set(f) - set(fd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Subject 1001 Data...\n",
      "Extract data complete.\n",
      "D:\\CIS-PD Study\\Data_dict\\1001dict.pkl\n",
      "D:\\CIS-PD Study\\Data_dict\\1001dict.pkl File Saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create data dict for remaining subjects\n",
    "data_all = []\n",
    "for SubID in list(set(f)-set(fd)):\n",
    "    print('Loading Subject ' + SubID + ' Data...')\n",
    "    act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "    print('Extract data complete.')\n",
    "    #save dict to Pickle file\n",
    "    #filename = dict_path+'\\\\'+SubID + 'dict.pkl'\n",
    "    filename = os.path.join(dict_path, SubID + 'dict.pkl')\n",
    "    print(filename)\n",
    "    f = open(filename,'wb')\n",
    "    pickle.dump(act_dict,f)\n",
    "    f.close()\n",
    "    print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
